{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJeiZJNNi0vrkqKMCZ+d2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiroto-noguchi/weekly_articles_2023/blob/main/weekly_article_2023_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOo6Y07GNcze"
      },
      "outputs": [],
      "source": [
        "#reをインポートする。\n",
        "import re\n",
        "#linguisticsが条件arch.+logyを満たせばオブジェクトを返す。\n",
        "re.search('arch.+logy', 'linguistics')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#archaeologyが条件arch.+logyを満たせばオブジェクトを返す。\n",
        "re.search('arch.+logy', 'archaeology')"
      ],
      "metadata": {
        "id": "yevF_B4TPkdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#マッチした文字列を返す。\n",
        "re.search('arch.+logy', 'archaeology').group()"
      ],
      "metadata": {
        "id": "tM5IwbOUPnKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#リスト中の単語のうち、arch.+logyを満たすものだけプリントする。\n",
        "words = ['arch', 'archaeology', 'biology']\n",
        "for word in words:\n",
        "  if re.search('arch.+logy', word):\n",
        "    print(re.search('arch.+logy', word).group())"
      ],
      "metadata": {
        "id": "af5q_aFEPp4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aとcのあいだに任意の1文字が入る文字列にマッチさせる。\n",
        "re.search('a.c', 'abc').group()"
      ],
      "metadata": {
        "id": "znl0bUQtPtt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aの後ろでaが1回以上繰り返されcに続く文字列にマッチさせる。\n",
        "re.search('a+c', 'aac').group()"
      ],
      "metadata": {
        "id": "gC-9Wb8fPwxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acもしくはaとcのあいだに任意の1文字が入る文字列にマッチさせる。\n",
        "re.search('a.?c', 'ac').group()"
      ],
      "metadata": {
        "id": "wpoCaKaLPzGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[]の中の文字1つとdの場合にマッチさせる。\n",
        "re.search('[abc]d', 'ad').group()"
      ],
      "metadata": {
        "id": "rtbPm5DUP1M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[]の中の文字以外とdの場合にマッチさせる。\n",
        "re.search('[^abc]d', 'dd').group()"
      ],
      "metadata": {
        "id": "qWXMJ50VP3x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#半角の数字にマッチさせる。\n",
        "re.search('[0-9]+', 'ab01２３').group()"
      ],
      "metadata": {
        "id": "Jwi20v03P5E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#半角数字とはさまれたひらがなを取り出す。\n",
        "re.search('[0-9][ぁ-ん]+[0-9]', 'aあいbう1えお2').group()"
      ],
      "metadata": {
        "id": "RAWk_SX3QUAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#後方参照を利用して、半角数字にはさまれたひらがなのみを取り出す。\n",
        "re.search('([0-9])([ぁ-ん]+)([0-9])', 'aあいbう1えお2').group(2)"
      ],
      "metadata": {
        "id": "VmNPXmMLQYB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#URLの末尾を引数にしてスクレイピングしたテキストを返す。\n",
        "def collect_texts(items):\n",
        "  import requests\n",
        "  from bs4 import BeautifulSoup\n",
        "  import time\n",
        "\n",
        "  text = ''\n",
        "  base = 'https://en.wikipedia.org/wiki/'\n",
        "\n",
        "  for item in items:\n",
        "    webpage = requests.get(base+item)\n",
        "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
        "    p_tags = soup.find_all('p')\n",
        "\n",
        "    for p_tag in p_tags:\n",
        "      text = text + p_tag.get_text().replace('\\n', ' ')\n",
        "    time.sleep(1)\n",
        "\n",
        "  return text\n",
        "\n",
        "#返ってきたテキストをtextに代入する。 \n",
        "text = collect_texts(['Language', 'English'])\n",
        "\n",
        "#40回以上出現するもののをプリントする。\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "freq = Counter(text.lower().split())\n",
        "df = pd.DataFrame.from_dict(freq, orient='index',columns=['frequency']).rename_axis('word')\n",
        "df[df['frequency'] >= 40].sort_values('frequency', ascending=False)"
      ],
      "metadata": {
        "id": "znzr5-_IQbY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordsのsを除去する\n",
        "re.sub('s$', '', 'words')"
      ],
      "metadata": {
        "id": "x8k01TM2Qwtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#語末のsを削除する。\n",
        "freq = Counter([re.sub('s$', '', word) for word in text.lower().split()])\n",
        "df = pd.DataFrame.from_dict(freq, orient='index',columns=['frequency']).rename_axis('word')\n",
        "df[df['frequency'] >= 40].sort_values('frequency', ascending=False)"
      ],
      "metadata": {
        "id": "bjnpGnwpRN7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#語末のesもしくはsを削除する。\n",
        "re.sub('e?s$', '', 'boxes')"
      ],
      "metadata": {
        "id": "IlmVdhKBRST6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iesをyに置き換える。\n",
        "re.sub('ies$', 'y', 'countries')"
      ],
      "metadata": {
        "id": "emD39jI0RV9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#正規表現を利用して屈折変化のsを処理する。\n",
        "words = [word.lower() for word in text.split()]\n",
        "words = [re.sub('ies$', 'y', word) for word in words]\n",
        "words = [re.sub('e?s$', '', word) for word in words]\n",
        "\n",
        "freq = Counter(words)\n",
        "df = pd.DataFrame.from_dict(freq, orient='index',columns=['frequency']).rename_axis('word')\n",
        "df[df['frequency'] >= 40].sort_values('frequency', ascending=False)"
      ],
      "metadata": {
        "id": "5X2Ro2lsRZaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#正規表現による処理を確認してみる。\n",
        "words = ['words', 'boxes', 'languages', 'countries', 'mice', 'tennis']\n",
        "words = [re.sub('ies$', 'y', word) for word in words]\n",
        "words = [re.sub('e?s$', '', word) for word in words]\n",
        "words"
      ],
      "metadata": {
        "id": "doMMAFWySr1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#必要なものをインポートおよびダウンロードする。\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#見出し語化する。\n",
        "WordNetLemmatizer().lemmatize(\"words\")"
      ],
      "metadata": {
        "id": "l_1gilx1Sx1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTKのWordNetLemmatizerを使用してみる。\n",
        "words = ['words', 'boxes', 'countries', 'languages', 'mice', 'tennis']\n",
        "words = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
        "words"
      ],
      "metadata": {
        "id": "MPCqESakS2wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTKのWordNetLemmatizerで処理してからグラフを描く。\n",
        "words = [word.lower() for word in text.split()]\n",
        "words = [WordNetLemmatizer().lemmatize(word) for word in words] \n",
        "\n",
        "freq = Counter(words)\n",
        "df = pd.DataFrame.from_dict(freq, orient='index',columns=['frequency']).rename_axis('word')\n",
        "df[df['frequency'] >= 40].sort_values('frequency', ascending=False).plot(kind='bar')"
      ],
      "metadata": {
        "id": "I_KtREFHS6xB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}